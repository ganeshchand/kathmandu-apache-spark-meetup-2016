{"cells":[{"cell_type":"markdown","source":["# **Save a Join as a Table in Python**\nThis notebook shows how to register a join statement of two tables as a new Spark SQL table. It's an illusrative example of how dataframes provide an interface to SQL, and how one can create SQL tables from Dataframe and issue queries against them. Powerful stuff!"],"metadata":{}},{"cell_type":"markdown","source":["### Registering a join as its own table can make your SQL statements easier to read.\nOr perhaps you want to query the joined table many times and want to save it as an independent table."],"metadata":{}},{"cell_type":"markdown","source":["### **Setup:** Create two test temporary tables which we can join."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import Row\n#create a dataframe with these rows\narray = [Row(key=\"a\", group=\"vowels\", value=1),\n         Row(key=\"b\", group=\"consonants\", value=2),\n         Row(key=\"c\", group=\"consonants\", value=3),\n         Row(key=\"d\", group=\"consonants\", value=4),\n         Row(key=\"e\", group=\"vowels\", value=5)]\ndataFrame = sqlContext.createDataFrame(sc.parallelize(array))\n#create the first table\ndataFrame.registerTempTable(\"table1\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql import Row\n#create the dataframe with these rows\narray = [Row(key=\"a\", word=\"apple\"),\n         Row(key=\"a\", word=\"arrow\"),\n         Row(key=\"b\", word=\"bat\"),\n         Row(key=\"b\", word=\"barn\"),\n         Row(key=\"c\", word=\"cat\"),\n         Row(key=\"d\", word=\"dog\"),\n         Row(key=\"e\", word=\"elephant\")]\ndataFrame = sqlContext.createDataFrame(sc.parallelize(array))\n#create the second table\ndataFrame.registerTempTable(\"table2\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%sql select table1.*, table2.word from table1 join table2 on table1.key = table2.key"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["### **Step 1:** Output the results of the join as a schemaRDD."],"metadata":{}},{"cell_type":"code","source":["## now we are creating an Dataframe schemaRDD with the sQL. Once we have an RDD we can then perform further transformation on it\n## notice the results from the above SQL query and the results from display(joinedRDD)\njoinedRDD = sqlContext.sql(\"select table1.*, table2.word from table1 join table2 on table1.key = table2.key\")\ndisplay(joinedRDD)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### **Step 2:** The schemaRDD of the joined data can be registered as a Spark SQL table as any other schemaRDD."],"metadata":{}},{"cell_type":"code","source":["joinedRDD.registerTempTable(\"pythonJoinTable\")"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["### **Step 3:** Now the join is a new table that you can query like any other table."],"metadata":{}},{"cell_type":"code","source":["%sql describe pythonJoinTable"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["%sql select * from pythonJoinTable where key = \"a\""],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"6 Save Join - py","notebookId":4071},"nbformat":4,"nbformat_minor":0}
